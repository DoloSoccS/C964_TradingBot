{
 "cells": [
  {
   "cell_type": "code",
   "id": "2cb6c033f0c533d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T04:57:54.951954Z",
     "start_time": "2025-06-15T04:57:53.136272Z"
    }
   },
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from Database.MongoDB_Connection import start_db\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "import talib as ta\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "532202d758ffa445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T04:58:14.487952Z",
     "start_time": "2025-06-15T04:58:14.477450Z"
    }
   },
   "source": [
    "# Connect to MongoDB\n",
    "db = start_db()\n",
    "db"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB\n",
      "Test entry exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'C964_Database')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a48bbb0ead2df9",
   "metadata": {},
   "source": [
    "#Tickers used for model training\n",
    "print(\"Reading list of tickers to be loaded.\")\n",
    "\n",
    "tickers = [\n",
    "    \"AAL\", \"AAPL\", \"ABEV\", \"ACHR\", \"ADBE\", \"ADT\", \"ADSK\", \"ALGN\", \"ALNY\", \"AMAT\",\n",
    "    \"AMCR\", \"AMD\", \"AMZN\", \"ANET\", \"APH\", \"ASML\", \"AUR\", \"AVGO\", \"AXP\", \"BA\",\n",
    "    \"BAC\", \"BAX\", \"BB\", \"BBD\", \"BDX\", \"BIIB\", \"BK\", \"BKNG\", \"BLK\", \"BMY\",\n",
    "    \"BTG\", \"C\", \"CAT\", \"CCL\", \"CDE\", \"CHTR\", \"CI\", \"CINF\", \"CMCSA\", \"CMI\",\n",
    "    \"CNH\", \"COF\", \"COP\", \"COST\", \"CPNG\", \"CRM\", \"CSCO\", \"CSX\", \"CTAS\", \"CVS\",\n",
    "    \"CVX\", \"CX\", \"D\", \"DD\", \"DE\", \"DG\", \"DHR\", \"DIS\", \"DJT\", \"DOV\",\n",
    "    \"DTE\", \"DUK\", \"EMR\", \"ENPH\", \"EOG\", \"EQIX\", \"ERIC\", \"ETN\", \"EXC\", \"F\",\n",
    "    \"FANG\", \"FAST\", \"FDX\", \"FE\", \"FIS\", \"FISV\", \"GAP\", \"GE\", \"GGB\", \"GILD\",\n",
    "    \"GIS\", \"GLW\", \"GM\", \"GME\", \"GOOG\", \"GOOGL\", \"GRAB\", \"GS\", \"HAL\", \"HBAN\",\n",
    "    \"HD\", \"HIMS\", \"HL\", \"HLN\", \"HOLX\", \"HON\", \"HOOD\", \"HPQ\", \"HPE\", \"IBM\",\n",
    "    \"IAG\", \"ICE\", \"ILMN\", \"INFA\", \"INTC\", \"INTU\", \"IONQ\", \"ISRG\", \"ITUB\", \"ITW\",\n",
    "    \"JNPR\", \"JWN\", \"K\", \"KGC\", \"KEY\", \"KLAC\", \"KMB\", \"KMI\", \"KO\", \"KR\",\n",
    "    \"LCID\", \"LIN\", \"LLY\", \"LMT\", \"LOW\", \"LRCX\", \"LUMN\", \"LUV\", \"LYFT\", \"LYG\",\n",
    "    \"MA\", \"MARA\", \"MCD\", \"MDLZ\", \"MDT\", \"MET\", \"MMM\", \"MO\", \"MRK\", \"MRVL\",\n",
    "    \"MS\", \"MSFT\", \"MSI\", \"MTB\", \"MU\", \"NEE\", \"NEM\", \"NFLX\", \"NIO\", \"NKE\",\n",
    "    \"NKLA\", \"NOK\", \"NOV\", \"NRG\", \"NSC\", \"NTAP\", \"NVDA\", \"NU\", \"NXE\", \"OKLO\",\n",
    "    \"PDD\", \"PCG\", \"PFE\", \"PLTR\", \"PONY\", \"PSLV\", \"PTEN\", \"QBTS\", \"RGTI\", \"RIOT\",\n",
    "    \"RIG\", \"RIVN\", \"RKLB\", \"SOUN\", \"SMCI\", \"SMR\", \"SNAP\", \"SOFI\", \"T\", \"TEM\",\n",
    "    \"TEVA\", \"TSLA\", \"UBER\", \"UAA\", \"UEC\", \"UNH\", \"VALE\", \"VOD\", \"VTRS\", \"WBD\",\n",
    "    \"WMB\", \"WMT\", \"WRD\", \"X\"\n",
    "]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "# Entering documents into database. Other fields will be added after they are calculated.\n",
    "\n",
    "print(\"Inserting documents into MongoDB.\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Gather 10 year historical data in 1-year intervals. progress=False is to stop the display of the progress bar while downloading\n",
    "        data = yf.download(ticker, period=\"10y\", interval=\"1d\", progress=False, auto_adjust=False)\n",
    "\n",
    "        if not data.empty:\n",
    "            # Move 'Date' from index to first column. Date is needed as a datapoint.\n",
    "            data.reset_index(inplace=True)\n",
    "            data[\"Ticker\"] = ticker\n",
    "\n",
    "            # This prevents the data from being formatted incorrectly. Each value needs to be a string type. This line breaks down the MultiIndex values returned by the pandas object\n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                data.columns = ['_'.join(filter(None, col)).strip() for col in data.columns]\n",
    "\n",
    "            # Create documents to enter into database\n",
    "            newDocs = data.to_dict(\"records\")\n",
    "\n",
    "            # Insert attributes into MongoDB\n",
    "            db.Finance_Data.insert_many(newDocs)\n",
    "            print(f\"Inserted {len(newDocs)} attributes for {ticker}.\")\n",
    "\n",
    "        # Timer to prevent rate limit on yfinance. This limiter will cause a multi-day lockout.\n",
    "        time.sleep(1.5)\n",
    "    except Exception as e:\n",
    "        print(f\"{ticker} had an error being inserted: {e}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d491272be2e1ce3",
   "metadata": {},
   "source": [
    "# Restructuring the document fields in the database. From the yfinance API the fields are labeled as \"close_{ticker}\". This needed to be changed since the subsequent actions need to be easily manipulated across all tickers. Having the fields set to simply 'Open', 'Close', etc. will allow batch processing to be less complex.\n",
    "print(\"Transforming field names.\")\n",
    "\n",
    "rename_fields = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "tickers = db.Finance_Data.distinct(\"Ticker\")\n",
    "\n",
    "for ticker in tickers:\n",
    "\n",
    "    for field in rename_fields:\n",
    "        old_field = f\"{field}_{ticker}\"\n",
    "        new_field = field\n",
    "        db.Finance_Data.update_many(\n",
    "            {old_field: {\"$exists\": True}},\n",
    "            {\"$rename\": {old_field: new_field}}\n",
    "        )\n",
    "    print(f\"Renamed fields for {ticker}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc2e88e08308dce0",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The next few sections will be for adding the additional columns to the database documents.\n",
    "The first one will add a \"Success\" column. This will be based on whether the stock's \"Close\" value is greater than the \"Open\" value.\n",
    "This is the only one that will require a manual calculation to be performed.\n",
    "Next, the \"Sentiment Score\" column will be added using the nltk package. This library aggregates a list of related news articles pertaining to the ticker symbol in question. A value will be produced from -1 to +1.\n",
    "The columns for SMA, EMA, RSI and MACD will use a group of values from the ticker symbol in order to make the calculations.\n",
    "This action will be performed using the TA-lib package.\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8ed3cbc48952b37",
   "metadata": {},
   "source": [
    "# Adding the 'Success' column\n",
    "print(\"Adding Success column to database.\")\n",
    "\n",
    "# Gather each documents Open and Close value. If Open < Close, then Success = 1. Otherwise, Success = 0.\n",
    "for doc in db.Finance_Data.find():\n",
    "    doc_close = doc.get(\"Close\")\n",
    "    doc_open = doc.get(\"Open\")\n",
    "\n",
    "    if doc_close is not None and doc_open is not None:\n",
    "        success_flag = 1 if doc_close > doc_open else 0\n",
    "        db.Finance_Data.update_one(\n",
    "            {\"_id\": doc[\"_id\"]},\n",
    "            {\"$set\": {\"Success\": success_flag}}\n",
    "        )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e6cada2c42f9cda",
   "metadata": {},
   "source": [
    "# Adding the 'Sentiment Score' column\n",
    "print(\"Adding sentiment score for each ticker.\")\n",
    "\n",
    "# VADER is the sentiment analysis tool used specifically for social media and other media-based works.\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize Sentiment Analyzer for using model against related news articles\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get list of tickers\n",
    "#tickers = db.Finance_Data.distinct(\"Ticker\")\n",
    "\n",
    "for ticker_symbol in tickers:\n",
    "    print(f\"Getting sentiment score for {ticker_symbol}\")\n",
    "    try:\n",
    "\n",
    "        # Gets all the news items for the ticker symbol\n",
    "        news_items = yf.Ticker(ticker_symbol).get_news(count=25)\n",
    "        print(f\"First check to see how many news items there are Ticker: {ticker_symbol}, News : {len(news_items)}\")\n",
    "\n",
    "        # Will be used to store a dictionary of dates:news summaries\n",
    "        news_articles = []\n",
    "\n",
    "        for item in news_items:\n",
    "            content = item.get(\"content\", {})  # Getting content dictionary from news list\n",
    "            if \"summary\" in content and \"pubDate\" in content:\n",
    "                print(\"adding articles\")\n",
    "                article_date = datetime.fromisoformat(content[\"pubDate\"].replace(\"Z\", \"\")).date()  # Transforming the date format to match yfinance date\n",
    "                news_articles.append({\"Article_Date\": article_date, \"Summary\": content[\"summary\"]})  # The content summary is what the analysis is based on\n",
    "            else:\n",
    "                print(\"There's the issue getting the summary or pubDate\")\n",
    "\n",
    "\n",
    "        # Calculate sentiment from the last 60 days. The time variable may be a bit difficult to gather with the date limitations in MongoDB along with the limitations from yfinance. This section furthers transforms the date value to enable processing with datetime library.\n",
    "        docs = db.Finance_Data.find({\"Ticker\": ticker_symbol})\n",
    "        for doc in docs:\n",
    "            doc_date = doc.get(\"Date\")\n",
    "\n",
    "            if isinstance(doc_date, datetime):\n",
    "                doc_date = doc_date.date()\n",
    "            elif isinstance(doc_date, str):\n",
    "                try:\n",
    "                    doc_date = datetime.strptime(doc_date, \"%Y-%m-%d\").date()\n",
    "                except:\n",
    "                    print(\"meh\")\n",
    "\n",
    "            start_range = doc_date - timedelta(days=60)\n",
    "\n",
    "            # Will be used to store the compound score of the sentiment for all documents for the specific ticker\n",
    "            compound_scores = []\n",
    "            for item in news_articles:\n",
    "\n",
    "                # Will skip if date is wrong. Should only apply if date was not given or incomplete date such as MM/YYYY is given.\n",
    "                if not isinstance(item[\"Article_Date\"], date):\n",
    "                    print(\"Invalid article date format. Skipping.\")\n",
    "                    continue\n",
    "                # Check to see if the news articles fall in the above date range. If so, add to compound scores list.\n",
    "                if start_range <= item[\"Article_Date\"] < doc_date:\n",
    "\n",
    "                    sentiment = sia.polarity_scores(item[\"Summary\"])\n",
    "                    compound_scores.append(sentiment[\"compound\"])\n",
    "\n",
    "\t\t    # Add the sentiment score for specific date if compound scores is populated.\n",
    "            if compound_scores:\n",
    "                average_sentiment = sum(compound_scores) / len(compound_scores)\n",
    "\n",
    "            else:\n",
    "                # Average of all articles for this ticker will be added if it cannot be applied to specific date.\n",
    "                if news_articles:\n",
    "                    overall_scores = [sia.polarity_scores(item[\"Summary\"])[\"compound\"] for item in news_articles]\n",
    "                    average_sentiment = sum(overall_scores) / len(overall_scores)\n",
    "                else:\n",
    "                    average_sentiment = 0.0  #  Average sentiment set to 0.0, \"neutral\", as well if no articles found at all.\n",
    "\n",
    "            # Update all documents for this ticker with sentiment score\n",
    "            db.Finance_Data.update_one(\n",
    "                {\"_id\": doc[\"_id\"]},\n",
    "                {\"$set\": {\"Sentiment\": average_sentiment}}\n",
    "            )\n",
    "        print(f\"Added sentiment score for {ticker_symbol}\")\n",
    "\n",
    "    # If there is no news available for given ticker due to exception, default sentiment is set to 0.1 for identifying logic issue instead of request issue.\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker_symbol}: {e}. Default sentiment value is 0.1.\")\n",
    "        db.Finance_Data.update_many(\n",
    "            {\"Ticker\": ticker_symbol},\n",
    "            {\"$set\": {\"Sentiment\": 0.1}}\n",
    "        )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c98109cc55576348",
   "metadata": {},
   "source": [
    "# Adding the columns for SMA (Simple Moving Average), EMA (Exponential Moving Average), RSI (Relative Strength Index) and MACD ( Moving Average Convergence/Divergence)\n",
    "# After initial model training results, added Williams %R(WILLR), Commodity Channel Index(CCI) and Average True Range(ATR)\n",
    "print(\"Adding technical indicators\")\n",
    "\n",
    "tickers = db.Finance_Data.distinct(\"Ticker\")\n",
    "for symbol in tickers:\n",
    "\n",
    "    # Converting to list and sorting by date so that each indicator aligns properly.\n",
    "    current = list(db.Finance_Data.find({\"Ticker\": symbol}).sort(\"Date\",1))\n",
    "    close = [doc[\"Close\"] for doc in current if \"Close\" in doc]\n",
    "    high = [doc[\"High\"] for doc in current if \"High\" in doc]\n",
    "    low = [doc[\"Low\"] for doc in current if \"Low\" in doc]\n",
    "\n",
    "    # TA-lib only uses ndArrays\n",
    "    npArrayClose = np.array(close)\n",
    "    npArrayHigh = np.array(high)\n",
    "    npArrayLow = np.array(low)\n",
    "\n",
    "    # Calling TA-lib functions to calculate indicators\n",
    "    SMA_values = ta.SMA(npArrayClose, timeperiod=30)\n",
    "    EMA_values = ta.EMA(npArrayClose, timeperiod=30)\n",
    "    RSI_values = ta.RSI(npArrayClose, timeperiod=30)\n",
    "    MACD_values, MACD_signal, _ = ta.MACD(npArrayClose, fastperiod=10, slowperiod=28, signalperiod=7)\n",
    "    WILLR_values = ta.WILLR(npArrayHigh, npArrayLow, npArrayClose, timeperiod=14)\n",
    "    CCI_values = ta.CCI(npArrayHigh, npArrayLow, npArrayClose, timeperiod=14)\n",
    "    ATR_values = ta.ATR(npArrayHigh, npArrayLow, npArrayClose, timeperiod=14)\n",
    "\n",
    "\n",
    "    # Iterating through document to add indicator value.\n",
    "    for i, doc in enumerate(current):\n",
    "        # Will be used to store all the key:value pairs for inserting document fields\n",
    "        insert = {}\n",
    "\n",
    "        # There may be a situation where the value is NaN after the 30-day point.\n",
    "        #SMA\n",
    "        if i < len(SMA_values) and SMA_values[i] is not np.nan:\n",
    "            insert[\"SMA\"] = float(SMA_values[i])\n",
    "        #EMA\n",
    "        if i < len(EMA_values) and EMA_values[i] is not np.nan:\n",
    "            insert[\"EMA\"] = float(EMA_values[i])\n",
    "        #RSI\n",
    "        if i < len(RSI_values) and RSI_values[i] is not np.nan:\n",
    "            insert[\"RSI\"] = float(RSI_values[i])\n",
    "        #MACD\n",
    "        if i < len(MACD_values) and MACD_values[i] is not np.nan:\n",
    "            insert[\"MACD\"] = float(MACD_values[i])\n",
    "        # WILLR\n",
    "        if i < len(WILLR_values) and WILLR_values[i] is not np.nan:\n",
    "            insert[\"WILLR\"] = float(WILLR_values[i])\n",
    "        # CCI\n",
    "        if i < len(CCI_values) and CCI_values[i] is not np.nan:\n",
    "            insert[\"CCI\"] = float(CCI_values[i])\n",
    "        # ATR\n",
    "        if i < len(ATR_values) and ATR_values[i] is not np.nan:\n",
    "            insert[\"ATR\"] = float(ATR_values[i])\n",
    "\n",
    "        # Insert values for document\n",
    "        db.Finance_Data.update_one({\"_id\": doc[\"_id\"]}, {\"$set\": insert})\n",
    "\n",
    "print(\"Finish\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
